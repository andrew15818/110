{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fbeb7ec-697d-406a-bc49-75d982115940",
   "metadata": {},
   "source": [
    "# Data Science Homework 4\n",
    "Try different imbalanced classification datasets using $k$-fold cross validation and various classification methods.\n",
    "TODO List:\n",
    "- Make sure we can open all the data as either DataFrame or nparray\n",
    "- Handle categorical data (tokenize, one-hot encoding, ....)\n",
    "- Split each dataset into training and testing dataset.\n",
    "- Perform any necessary sampling, imputaiton, encoding techniques depending on dataset\n",
    "- Perform 5-fold cross-validation to select datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3197ea94-1d37-4113-baf2-de091cac66a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['covtype.data', 'dataset', 'biodeg.csv', 'eeg_eye_state.arff', 'heart_2020_cleaned.csv', 'phpAmSP4g.arff', 'WA_Fn-UseC_-Telco-Customer-Churn.csv', 'WineQT.csv', 'HTRU_2.csv', 'spambase.data', 'Raisin_Dataset.arff', 'UCI_Credit_Card.csv', 'income_evaluation.csv', 'abalone.data', 'arcene_train.data']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import category_encoders as ce # sklearn library\n",
    "import xgboost\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "DATA_DIR = './data'\n",
    "files = os.listdir(DATA_DIR)\n",
    "if '.ipynb_checkpoints' in files:\n",
    "    files.remove('.ipynb_checkpoints')\n",
    "\n",
    "special_delims = { 'arcene_train.data': ' '}\n",
    "no_headers = ['covtype.data', 'arcene_train.data']\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4815b9fb-5923-4120-9df7-0bbf3ffe073a",
   "metadata": {},
   "source": [
    "## Load datasets\n",
    "Some datasets are in csv format, others have just the data. First convert to `DataFrame`s to allow for numeric, categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cd7606-affa-4a6b-a7de-265d2703dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load(name, header=True):\n",
    "    sep = special_delims[name] if name in special_delims else ','\n",
    "    name = os.path.join(DATA_DIR, name)\n",
    "    if header:\n",
    "        df = pd.read_csv(name, sep=sep)\n",
    "    else:\n",
    "        df = pd.read_csv(name, header=None, sep=sep)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6ed6f-5619-4bd8-bd2b-ec3f64277958",
   "metadata": {},
   "source": [
    "## Encode Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01a3a02f-649f-45ea-9efc-a9c014157915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_per_column(data, encoder):\n",
    "    for column in data.columns:\n",
    "        data[column] = encoder.fit_transform(data[column])\n",
    "    return data\n",
    "        \n",
    "def encode_categorical(data:pd.DataFrame, method='ordinal'):\n",
    "    if method == 'ordinal':\n",
    "        encoder = ce.OrdinalEncoder()\n",
    "    elif method == 'onehot':\n",
    "        encoder = ce.OneHotEncoder()\n",
    "    elif method == 'label':\n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "        return encode_per_column(data,encoder)\n",
    "    elif method == 'feature':\n",
    "        encoder = FeatureHasher(n_features=10, input_type='string')\n",
    "        encoder.transform(data.type)\n",
    "    elif method == 'target':\n",
    "        encoder = ce.target_encoder.TargetEncoder()\n",
    "        y = data.iloc[:,-1]\n",
    "        return encoder.fit_transform(data.iloc[:,:-1], y)\n",
    "    elif method == 'leaveoneout':\n",
    "        y = data.iloc[:,-1]\n",
    "        encoder = ce.LeaveOneOutEncoder()\n",
    "        return encoder.fit_transform(data.iloc[:,:-1], y)\n",
    "    elif method == 'frequency':\n",
    "        encoder = ce.CountEncoder()\n",
    "    return encoder.fit_transform(data)\n",
    "\n",
    "def scale_features(data:pd.DataFrame, method='standard') -> pd.DataFrame:\n",
    "    if method == 'standard':\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "    elif method == 'minmax':\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "    return scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb65dd-2d12-4851-9783-037c307c731b",
   "metadata": {},
   "source": [
    "## Train model:\n",
    "The evalutation should be fixed on 5-fold cross validation, choose from `RandomForest`, `GBDT`, `XGBoost`,`LightBGM`, `CatBoost`, `KNN`, `Logistic Regression`,`MLP`, `SVM`.\n",
    "\n",
    "Train a new model every iteration of the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f52818bb-a52f-4e49-90d3-aa1008e90157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model(method):\n",
    "    if method == 'xgboost':\n",
    "        model = xgboost.XGBClassifier(5)\n",
    "    elif method == 'knn':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif method == 'forest':\n",
    "        model = RandomForestClassifier(10)\n",
    "    elif method == 'lightgbm':\n",
    "        model = lgb\n",
    "    \n",
    "    else:\n",
    "        print(f'{method} not supported.')\n",
    "        model = None\n",
    "    return model\n",
    "\n",
    "def get_metric(method):\n",
    "    if method == 'acc':\n",
    "        met = metrics.accuracy_score\n",
    "    elif method == 'auc':\n",
    "        met = metrics.auc\n",
    "    elif method == 'roc_auc':\n",
    "        met = metrics.roc_auc_score\n",
    "    elif method == 'f1':\n",
    "        met = metrics.f1_score\n",
    "    return met\n",
    "\n",
    "def train(x, y, method='xgboost', metric='acc'):\n",
    "    # Perform K-Fold cross validation\n",
    "    metric = get_metric(metric)\n",
    "    n_items = x.shape[0]\n",
    "    kf = KFold( n_splits=5, shuffle=True)\n",
    "    \n",
    "    mean_score = 0 \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "        model = get_model(method)\n",
    "        x_train, x_test = x.iloc[train_index,: ], x.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        if method == 'xgboost':\n",
    "            y_train -= 1 # Class labels should be zero-based\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        preds = model.predict(x_test)\n",
    "        score = metric(y_test, preds)\n",
    "        mean_score += score\n",
    "        #print(f'\\t{mean_score}')\n",
    "        \n",
    "    mean_score /= (i+1)\n",
    "    #print(f'Mean score over validation: {mean_score} using {method}')\n",
    "\n",
    "    return mean_score\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570aa398-74ca-476c-ab9c-1b703a1cae20",
   "metadata": {},
   "source": [
    "## P1: How does feature scaling (e.g. performing normalization) affect performance?\n",
    "With standardization we apply the formula\n",
    "$$x' = \\frac{x - \\mu}{\\sigma}$$\n",
    "so that we have 0 mean in the training data.\n",
    "\n",
    "For One-hot Encoding we should not use this with tree-based models. For these models we can use label encoding, feature-hashing.\n",
    "We should first encode the categorical values, then train the models on all our datasets both with feature scaling and without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d8aa7e-001d-4e4b-9b41-400240cce3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on covtype.data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mknn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43macc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: avg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m score \u001b[38;5;241m=\u001b[39m train(control, c_labels, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknn\u001b[39m\u001b[38;5;124m'\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(x, y, method, metric)\u001b[0m\n\u001b[1;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m score \u001b[38;5;241m=\u001b[39m metric(y_test, preds)\n\u001b[1;32m     43\u001b[0m mean_score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m score\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:214\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m        Class labels for each data sample.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     neigh_dist, neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    216\u001b[0m     _y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_base.py:752\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    750\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[0;32m--> 752\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1717\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1716\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[0;32m-> 1717\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1719\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1889\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m   1887\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m-> 1889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1430\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1427\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1433\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:330\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m         )\n\u001b[0;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:371\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    368\u001b[0m     distances \u001b[38;5;241m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[1;32m    373\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/extmath.py:156\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 156\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    160\u001b[0m ):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_base.py:1291\u001b[0m, in \u001b[0;36misspmatrix\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1288\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m-> 1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misspmatrix\u001b[39m(x):\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;124;03m\"\"\"Is x of a sparse matrix type?\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, spmatrix)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    \n",
    "    df = load(file, False if file in no_headers else True)\n",
    "    # Encode categorical columns\n",
    "    cats = df.select_dtypes(include=['object'])\n",
    "    df[cats.columns] = encode_categorical(cats)\n",
    "    \n",
    "    control = df.copy(deep=True) # Compare with standardized dataset\n",
    "\n",
    "    df, labels = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "    control, c_labels = control.iloc[:, :-1], control.iloc[:, -1]\n",
    "    \n",
    "    # Feature scaling\n",
    "    df = pd.DataFrame(scale_features(df))\n",
    "    \n",
    "    # Train model\n",
    "    print(f'Training on {file}')\n",
    "    score = train(df, labels, method='knn', metric='acc')\n",
    "    print(f'train: {file}: avg: {score}')\n",
    "   \n",
    "    score = train(control, c_labels, method='knn', metric='acc')\n",
    "    print(f'test: {file}: avg: {score}')\n",
    "    print('\\n')\n",
    "    # The performance is mostly the same across models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aad0b2",
   "metadata": {},
   "source": [
    "## P2 When using tree-based algorithms, will usng one-hot encoding for categorical features generate worse performance than using label encoding? Why?\n",
    "One-hot encoding transforms inputs with a range of $(1,\\dots,n)$. This method generates extra columns and usually results in a sparse matrix.\n",
    "\n",
    "Label Encoding adds replaces each unique class name with an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc1a45-e699-414f-8259-00d78398f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    df = load(file, False if file in no_headers else True)\n",
    "    target_column = df.columns[-1]\n",
    "    label = df.copy(deep=True) # Use label encoding\n",
    "    \n",
    "    cats = df.select_dtypes(include=['object'])\n",
    "\n",
    "    # Ignore files w/ no categorical data, otherw encoder error\n",
    "    if cats.empty:\n",
    "        print(f'No categorical in {file}\\n')\n",
    "        continue\n",
    "        \n",
    "    n_unique = df[target_column].unique().shape[0] # Num of unique items in target column\n",
    "\n",
    "    one_hot = pd.get_dummies(df)\n",
    "    cats = label.select_dtypes(include=['object'])\n",
    "    #print(f'{file}: {target_column}')\n",
    "    # Apply Label Encoder to each column\n",
    "    for column in cats.columns:\n",
    "        label[column] = encode_categorical(label[column], method='label')\n",
    "        \n",
    "    # If target column is not categorical, labels will only be one column\n",
    "    if df.dtypes[target_column] == object:\n",
    "        n_unique = df[target_column].unique().shape[0]\n",
    "    else:\n",
    "        n_unique = 1\n",
    "    \n",
    "    x_ohe, y_ohe = one_hot.iloc[:,:-n_unique], one_hot.iloc[:,-n_unique:]\n",
    "    x_label, y_label = label.iloc[:,:-1], label.iloc[:,-1]\n",
    "    \n",
    "    #print(f'{file}: xcols: {len(x_label)} ycols: {len(y_label)}')\n",
    "    #print(one_hot)\n",
    "    print(f'Training on {file}')\n",
    "    score = train(x_ohe, y_ohe, method='forest', metric='acc')\n",
    "    print(f'train: {file}: avg: {score}')\n",
    "    \n",
    "    score = train(x_label, y_label, method='forest', metric='acc')\n",
    "    print(f'test: {file}: avg: {score}')\n",
    "    print('\\n')\n",
    "    ## There is a slight difference in performance (label encoder usually better by a bit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9237acb9-d3f7-46f9-8114-72f6010104c9",
   "metadata": {},
   "source": [
    "## P3\n",
    "Will feature binning provide performance improvement? When is binning useful (which models or which kinds of datasets)?\n",
    "\n",
    "Loop through each column in the dataframe and bin individually.\n",
    "We use LabelEncoder for categorical features on both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dcdbe8-67ee-4764-8212-9f24ea33daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    df = load(file, False if file in no_headers else True)\n",
    "    binned = df.copy(deep=True)\n",
    "    # TODO: fix arcene random space unable to parse\n",
    "    if file == 'arcene_train.data':\n",
    "        continue\n",
    "    # Bin each column individually, use LabelEncoder for categorical\n",
    "    for column in binned.columns:\n",
    "        if (binned[column].dtype.name == 'int64'\n",
    "           or binned[column].dtype.name == 'float64'):\n",
    "            #n_unique = binned[column].unique() \n",
    "            binned[column]= pd.cut(binned[column], 5, labels=False, duplicates='drop')\n",
    "            #binned[column].fillna(0, inplace=True)\n",
    "\n",
    "            if binned[column].isnull().values.any():\n",
    "                binned[colum] = 0\n",
    "        #elif check if column is categorical\n",
    "        elif binned[column].dtype.name == 'object':\n",
    "            binned[column] = encode_categorical(binned[column], method='label')\n",
    "            df[column] = encode_categorical(df[column], method='ordinal')\n",
    "\n",
    "    # Train\n",
    "    x_bin, y_bin = binned.iloc[:, :-1], binned.iloc[:, -1]\n",
    "    x_label, y_label = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "    \n",
    "    print(f'Training on {file}')\n",
    "    score = train(x_bin, y_bin, method='forest', metric='acc')\n",
    "    print(f'train: {file}: avg: {score}')\n",
    "    \n",
    "    score = train(x_label, y_label, method='forest', metric='acc')\n",
    "    print(f'test: {file}: avg: {score}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e941f-c7b6-49e2-9f0b-db9271a52a80",
   "metadata": {},
   "source": [
    "## P4\n",
    "Compare the performance of 6 different categorical feature encoding methods based on Random Forest, XGBoost LightGBM, MLP, SVM. Which of the 6 encoding methods is better?\n",
    "\n",
    "Models to test: \n",
    "1. One hot encoding\n",
    "2. Label Encoding\n",
    "3. Feature Hasing\n",
    "4. Frequency Encoding\n",
    "5. Target Encoding\n",
    "6. Leave One Out Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8671b37-af75-4c5f-850e-b0194e58641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking covtype.data\n",
      "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "            51, 52, 53, 54],\n",
      "           dtype='int64')\n",
      "Using leaveoneout\n",
      "forest\n",
      "xgboost\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking dataset\n",
      "Index(['month', 'credit_amount', 'credit_term', 'age', 'sex', 'education',\n",
      "       'product_type', 'having_children_flg', 'region', 'income',\n",
      "       'family_status', 'phone_operator', 'is_client', 'bad_client_target'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "forest\n",
      "xgboost\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking biodeg.csv\n",
      "Index(['SpMax_L', 'J_Dz(e)', 'nHM', 'F01[N-N]', 'F04[C-N]', 'NssssC', 'nCb-',\n",
      "       'C%', 'nCp', 'n)', 'F03[C-N]', 'SdssC', 'HwWi_B(m)', 'LOC', 'SM6_L',\n",
      "       'F03[C-O]', 'Me', 'Mi', 'nN-N', 'nArNO2', 'nCRX3', 'SpPosA_B(p)',\n",
      "       'nCIR', 'B01[C-BR]', 'B03[C-CI]', 'N-073', 'SpMax_A', 'Psi_i_1d',\n",
      "       'B04[C-Br]', 'SdO', 'Ti2_L', 'nCrt', 'C-026', 'F02[C-N]', 'nHDon',\n",
      "       'SpMax_B(m)', 'Psi_i_A', 'nN', 'SM6_B(m)', 'nArCOOR', 'nX', 'class'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking eeg_eye_state.arff\n",
      "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
      "       'V12', 'V13', 'V14', 'Class'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "forest\n",
      "xgboost\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking heart_2020_cleaned.csv\n",
      "Index(['HeartDisease', 'BMI', 'Smoking', 'AlcoholDrinking', 'Stroke',\n",
      "       'PhysicalHealth', 'MentalHealth', 'DiffWalking', 'Sex', 'AgeCategory',\n",
      "       'Race', 'Diabetic', 'PhysicalActivity', 'GenHealth', 'SleepTime',\n",
      "       'Asthma', 'KidneyDisease', 'SkinCancer'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking phpAmSP4g.arff\n",
      "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
      "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
      "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V20.1',\n",
      "       'Class'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "forest\n",
      "xgboost\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
      "Index(['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
      "       'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
      "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
      "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
      "       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking WineQT.csv\n",
      "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality', 'Id'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "forest\n",
      "xgboost\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking HTRU_2.csv\n",
      "Index(['140.5625', '55.68378214', '-0.234571412', '-0.699648398',\n",
      "       '3.199832776', '19.11042633', '7.975531794', '74.24222492', '0'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "forest\n",
      "xgboost\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking spambase.data\n",
      "Index(['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
      "       'word_freq_our', 'word_freq_over', 'word_freq_remove',\n",
      "       'word_freq_internet', 'word_freq_order', 'word_freq__mail',\n",
      "       'word_freq_receive', 'word_freq_will', 'word_freq_people',\n",
      "       'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n",
      "       'word_freq_business', 'word_freq_email', 'word_freq_you',\n",
      "       'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000',\n",
      "       'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george',\n",
      "       'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet',\n",
      "       'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n",
      "       'word_freq_technology', 'word_freq_1999', 'word_freq_parts',\n",
      "       'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting',\n",
      "       'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
      "       'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
      "       'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!',\n",
      "       'char_freq_$', 'char_freq_#', 'capital_run_length_avergage',\n",
      "       'captial_run_length_longest', 'capital_run_length_total'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "forest\n",
      "xgboost\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking Raisin_Dataset.arff\n",
      "Index(['Area', 'MajorAxisLength', 'MinorAxisLength', 'Ecentrictiy',\n",
      "       'ConvexArea', 'Extent', 'Perimeter', 'Class'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking UCI_Credit_Card.csv\n",
      "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
      "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
      "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
      "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
      "       'default.payment.next.month'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "forest\n",
      "xgboost\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking income_evaluation.csv\n",
      "Index(['age', ' workclass', ' fnlwgt', ' education', ' education-num',\n",
      "       ' marital-status', ' occupation', ' relationship', ' race', ' sex',\n",
      "       ' capital-gain', ' capital-loss', ' hours-per-week', ' native-country',\n",
      "       ' income'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking abalone.data\n",
      "Index(['Sex', 'Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight',\n",
      "       'Viscera weight', 'Shell weight', 'Rings'],\n",
      "      dtype='object')\n",
      "Using leaveoneout\n",
      "forest\n",
      "xgboost\n",
      "Using frequency\n",
      "forest\n",
      "xgboost\n",
      "Checking arcene_train.data\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChecking \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mno_headers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     cats \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, header)\u001b[0m\n\u001b[1;32m      5\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(name, sep\u001b[38;5;241m=\u001b[39msep)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1231\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:75\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:551\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "ceMethods = [#'onehot',\n",
    "              #'label',\n",
    "              #'feature',\n",
    "              #'target',\n",
    "              'leaveoneout',\n",
    "              'frequency'\n",
    "             ]\n",
    "modelNames = ['forest',\n",
    "             'xgboost',\n",
    "             #'lightgbm',\n",
    "             #'MLP',\n",
    "             #'SVM'\n",
    "            ]\n",
    "\n",
    "for file in files:\n",
    "    print(f'Checking {file}')\n",
    "    df = load(file, header = False if file in no_headers else True)\n",
    "    cats = df.select_dtypes(include=['object'])\n",
    "    print(df.columns)\n",
    "    for method in ceMethods:\n",
    "        # Encode features\n",
    "        print(f'Using {method}')\n",
    "        encoded = df.copy()\n",
    "        try:\n",
    "            encode_categorical(encoded, method=method)\n",
    "        except:\n",
    "            continue\n",
    "        for modelName in modelNames:\n",
    "            \n",
    "            print(modelName)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84647f53-a684-4846-965b-ea3354c23808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41309118-82c9-45a7-901d-f5486a76c1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
