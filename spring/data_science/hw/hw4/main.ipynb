{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fbeb7ec-697d-406a-bc49-75d982115940",
   "metadata": {},
   "source": [
    "# Data Science Homework 4\n",
    "Try different imbalanced classification datasets using $k$-fold cross validation and various classification methods.\n",
    "TODO List:\n",
    "- Make sure we can open all the data as either DataFrame or nparray\n",
    "- Handle categorical data (tokenize, one-hot encoding, ....)\n",
    "- Split each dataset into training and testing dataset.\n",
    "- Perform any necessary sampling, imputaiton, encoding techniques depending on dataset\n",
    "- Perform 5-fold cross-validation to select datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e10d493c-9513-4d05-a216-63e80d4ab3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "import lightgbm as lgb\n",
    "import neuralnet # My simple nn\n",
    "import sklearn.svm as svm\n",
    "import sklearn.metrics as metrics\n",
    "import category_encoders as ce # sklearn library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split,  StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "DATA_DIR = './data'\n",
    "files = os.listdir(DATA_DIR)\n",
    "if '.ipynb_checkpoints' in files:\n",
    "    files.remove('.ipynb_checkpoints')\n",
    "\n",
    "special_delims = { 'arcene_train.data': ' '}\n",
    "no_headers = ['covtype.data', 'arcene_train.data']\n",
    "\n",
    "numMethods = ['clip',\n",
    "              'standard',\n",
    "              'minmax',\n",
    "              'bin',\n",
    "              'rank'\n",
    "            ]\n",
    "ceMethods = ['onehot',\n",
    "              'label',\n",
    "              'feature',\n",
    "              'target',\n",
    "              'leaveoneout',\n",
    "              'frequency'\n",
    "             ]\n",
    "modelNames = ['forest',\n",
    "             'xgboost',\n",
    "             'lightgbm',\n",
    "             'mlp',\n",
    "             'svm'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4815b9fb-5923-4120-9df7-0bbf3ffe073a",
   "metadata": {},
   "source": [
    "## Load datasets\n",
    "Some datasets are in csv format, others have just the data. First convert to `DataFrame`s to allow for numeric, categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cd7606-affa-4a6b-a7de-265d2703dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load(name, header=True):\n",
    "    sep = special_delims[name] if name in special_delims else ','\n",
    "    name = os.path.join(DATA_DIR, name)\n",
    "    if header:\n",
    "        df = pd.read_csv(name, sep=sep)\n",
    "    else:\n",
    "        df = pd.read_csv(name, header=None, sep=sep)\n",
    "    \n",
    "    # Move target column to last\n",
    "    if  'WineQT.csv' in name:\n",
    "        cols = list(df.columns)\n",
    "        x, y = cols.index('quality'), cols.index('Id')\n",
    "        cols[x], cols[y] = cols[y], cols[x]\n",
    "        df = df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6ed6f-5619-4bd8-bd2b-ec3f64277958",
   "metadata": {},
   "source": [
    "## Encode Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01a3a02f-649f-45ea-9efc-a9c014157915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_per_column(data, encoder):\n",
    "    for column in data.columns:\n",
    "        data.loc[:, column] = encoder.fit_transform(data.loc[:, column])\n",
    "    return data\n",
    "        \n",
    "def encode_categorical(data:pd.DataFrame, method='ordinal', y=None):\n",
    "    if method == 'ordinal':\n",
    "        encoder = ce.OrdinalEncoder()\n",
    "    elif method == 'onehot':\n",
    "        encoder = ce.OneHotEncoder()\n",
    "    elif method == 'label':\n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "        #return encode_per_column(data,encoder)\n",
    "    elif method == 'feature':\n",
    "        encoder = FeatureHasher(n_features=10, input_type='string')\n",
    "        encoder.transform(data.type)\n",
    "    elif method == 'target':\n",
    "        encoder = ce.target_encoder.TargetEncoder()\n",
    "        \n",
    "        return encoder.fit_transform(data.iloc[:, :-1], y)\n",
    "    elif method == 'leaveoneout':\n",
    "        y = data.iloc[:,-1]\n",
    "        encoder = ce.LeaveOneOutEncoder()\n",
    "        return encoder.fit_transform(data.iloc[:,:-1], y)\n",
    "    elif method == 'frequency':\n",
    "        encoder = ce.CountEncoder()\n",
    "    return encoder.fit_transform(data)\n",
    "\n",
    "def scale_features(data:pd.DataFrame, method='standard') -> pd.DataFrame:\n",
    "    if method == 'standard':\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "    elif method == 'minmax':\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "    elif method == 'clip':\n",
    "        for column in data.columns:\n",
    "            p01 = data[column].quantile(.01)\n",
    "            p99 = data[column].quantile(.99)\n",
    "            data[column].clip(p01, p99)\n",
    "        return data\n",
    "    elif method == 'bin':\n",
    "        for column in data.columns:\n",
    "            data.loc[:, column] = pd.cut(data.loc[:, column], 5, labels=False, duplicates='drop')\n",
    "        return data\n",
    "    elif method == 'rank':\n",
    "        for column in data.columns:\n",
    "            data.loc[:, column] = data[column].rank()\n",
    "        return data\n",
    "    \n",
    "    return scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb65dd-2d12-4851-9783-037c307c731b",
   "metadata": {},
   "source": [
    "## Train model:\n",
    "The evalutation should be fixed on 5-fold cross validation, choose from `RandomForest`, `GBDT`, `XGBoost`,`LightBGM`, `CatBoost`, `KNN`, `Logistic Regression`,`MLP`, `SVM`.\n",
    "\n",
    "Train a new model every iteration of the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f52818bb-a52f-4e49-90d3-aa1008e90157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model(method):\n",
    "    if method == 'xgboost':\n",
    "        model = xgboost.XGBClassifier(5)\n",
    "    elif method == 'knn':\n",
    "        model = KNeighborsClassifier(n_neighbors=3)\n",
    "    elif method == 'forest':\n",
    "        model = RandomForestClassifier(10)\n",
    "    elif method == 'lightgbm':\n",
    "        model = lgb\n",
    "    elif method == 'mlp':\n",
    "        model = neuralnet.tabularNet()\n",
    "    elif method == 'svm':\n",
    "        model = svm.SVC()\n",
    "    else:\n",
    "        print(f'{method} not supported.')\n",
    "        model = None\n",
    "    return model\n",
    "\n",
    "def get_metric(method):\n",
    "    if method == 'acc':\n",
    "        met = metrics.accuracy_score\n",
    "    elif method == 'auc':\n",
    "        met = metrics.auc\n",
    "    elif method == 'roc_auc':\n",
    "        met = metrics.roc_auc_score\n",
    "    elif method == 'f1':\n",
    "        met = metrics.f1_score\n",
    "    elif method == 'prc':\n",
    "        met = metrics.precision_recall_f1_support\n",
    "    return met\n",
    "\n",
    "def train(x, y, method='xgboost', metric='acc'):\n",
    "    # Perform K-Fold cross validation\n",
    "    metric = get_metric(metric)\n",
    "    n_items = x.shape[0]\n",
    "    kf = StratifiedKFold( n_splits=5, shuffle=True)\n",
    "    model = get_model(method)\n",
    "    mean_score = cross_val_score(model, x, y, cv=kf, n_jobs=1)\n",
    "    '''\n",
    "    mean_score = 0 \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x, y)):\n",
    "        model = get_model(method)\n",
    "        x_train, x_test = x.iloc[train_index,: ], x.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # \n",
    "        try:\n",
    "            if y_test.min().item()  != 0 and method == 'xgboost':\n",
    "                y_train -= y_train.min().item() # Class labels should be zero-based\n",
    "        except ValueError:\n",
    "            pass\n",
    "            \n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        preds = model.predict(x_test)\n",
    "        score = metric(y_test, preds)\n",
    "        mean_score += score\n",
    "        \n",
    "    mean_score /= (i+1)\n",
    "    #print(f'Mean score over validation: {mean_score} using {method}')\n",
    "    '''\n",
    "    return mean_score.mean(axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570aa398-74ca-476c-ab9c-1b703a1cae20",
   "metadata": {},
   "source": [
    "## P1: How does feature scaling (e.g. performing normalization) affect performance?\n",
    "With standardization we apply the formula\n",
    "$$x' = \\frac{x - \\mu}{\\sigma}$$\n",
    "so that we have 0 mean in the training data.\n",
    "\n",
    "For One-hot Encoding we should not use this with tree-based models. For these models we can use label encoding, feature-hashing.\n",
    "We should first encode the categorical values, then train the models on all our datasets both with feature scaling and without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9d8aa7e-001d-4e4b-9b41-400240cce3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on abalone.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: abalone.data: avg: 0.22624301635962524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: abalone.data: avg: 0.22719107240065325\n",
      "\n",
      "\n",
      "Training on bands.data\n",
      "train: bands.data: avg: 0.7651715936119606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: bands.data: avg: 0.7856269113149846\n",
      "\n",
      "\n",
      "Training on biodeg.csv\n",
      "train: biodeg.csv: avg: 0.8473933649289099\n",
      "test: biodeg.csv: avg: 0.8530805687203792\n",
      "\n",
      "\n",
      "Training on covtype.data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43macc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: avg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m score \u001b[38;5;241m=\u001b[39m train(control, c_labels, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforest\u001b[39m\u001b[38;5;124m'\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(x, y, method, metric)\u001b[0m\n\u001b[0;32m     36\u001b[0m kf \u001b[38;5;241m=\u001b[39m StratifiedKFold( n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(method)\n\u001b[1;32m---> 38\u001b[0m mean_score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03mmean_score = 0 \u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03mfor i, (train_index, test_index) in enumerate(kf.split(x, y)):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m#print(f'Mean score over validation: {mean_score} using {method}')\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mean_score\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    507\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 509\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 267\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    442\u001b[0m ]\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    \n",
    "    df = load(file, False if file in no_headers else True)\n",
    "    # Encode categorical columns\n",
    "    cats = df.select_dtypes(include=['object'])\n",
    "    df[cats.columns] = encode_categorical(cats)\n",
    "    \n",
    "    control = df.copy(deep=True) # Compare with standardized dataset\n",
    "\n",
    "    df, labels = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "    control, c_labels = control.iloc[:, :-1], control.iloc[:, -1]\n",
    "    \n",
    "    # Feature scaling\n",
    "    df = pd.DataFrame(scale_features(df))\n",
    "    \n",
    "    # Train model\n",
    "    print(f'Training on {file}')\n",
    "    score = train(df, labels, method='forest', metric='acc')\n",
    "    print(f'train: {file}: avg: {score}')\n",
    "   \n",
    "    score = train(control, c_labels, method='forest', metric='acc')\n",
    "    print(f'test: {file}: avg: {score}')\n",
    "    print('\\n')\n",
    "    # The performance is mostly the same across models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aad0b2",
   "metadata": {},
   "source": [
    "## P2 When using tree-based algorithms, will usng one-hot encoding for categorical features generate worse performance than using label encoding? Why?\n",
    "One-hot encoding transforms inputs with a range of $(1,\\dots,n)$. This method generates extra columns and usually results in a sparse matrix.\n",
    "\n",
    "Label Encoding adds replaces each unique class name with an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d1bc1a45-e699-414f-8259-00d78398f75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on abalone.data\n",
      "\tOnehot avg: 0.9971274675529325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tlabel avg: 0.23366558748531646\n",
      "\n",
      "\n",
      "Training on bands.data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:822\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 822\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ready_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;66;03m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#print(f'{file}: xcols: {len(x_label)} ycols: {len(y_label)}')\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#print(one_hot)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_ohe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ohe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mknn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43macc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mOnehot avg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m score \u001b[38;5;241m=\u001b[39m train(x_label, y_label, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforest\u001b[39m\u001b[38;5;124m'\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(x, y, method, metric)\u001b[0m\n\u001b[0;32m     36\u001b[0m kf \u001b[38;5;241m=\u001b[39m StratifiedKFold( n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(method)\n\u001b[1;32m---> 38\u001b[0m mean_score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03mmean_score = 0 \u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03mfor i, (train_index, test_index) in enumerate(kf.split(x, y)):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m#print(f'Mean score over validation: {mean_score} using {method}')\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mean_score\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    507\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 509\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 267\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:833\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    830\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    831\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[1;32m--> 833\u001b[0m islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(islice) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 267\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    268\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    269\u001b[0m         clone(estimator),\n\u001b[0;32m    270\u001b[0m         X,\n\u001b[0;32m    271\u001b[0m         y,\n\u001b[0;32m    272\u001b[0m         scorers,\n\u001b[0;32m    273\u001b[0m         train,\n\u001b[0;32m    274\u001b[0m         test,\n\u001b[0;32m    275\u001b[0m         verbose,\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    277\u001b[0m         fit_params,\n\u001b[0;32m    278\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    279\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    280\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    281\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    284\u001b[0m )\n\u001b[0;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:340\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    334\u001b[0m         (\n\u001b[0;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    336\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    338\u001b[0m     )\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:86\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     84\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m     85\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[0;32m     87\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[0;32m     88\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:709\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 709\u001b[0m     test_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits):\n\u001b[0;32m    711\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m test_folds \u001b[38;5;241m==\u001b[39m i\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    650\u001b[0m allowed_target_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_of_target_y \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_target_types:\n\u001b[1;32m--> 652\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported target types are: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    654\u001b[0m             allowed_target_types, type_of_target_y\n\u001b[0;32m    655\u001b[0m         )\n\u001b[0;32m    656\u001b[0m     )\n\u001b[0;32m    658\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y)\n\u001b[0;32m    660\u001b[0m _, y_idx, y_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead."
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    df = load(file, False if file in no_headers else True)\n",
    "    target_column = df.columns[-1]\n",
    "    label = df.copy(deep=True) # Use label encoding\n",
    "    \n",
    "    cats = label.select_dtypes(include=['object'])\n",
    "\n",
    "    # Ignore files w/ no categorical data, otherw encoder error\n",
    "    if cats.empty:\n",
    "        print(f'No categorical in {file}\\n')\n",
    "        continue\n",
    "        \n",
    "    one_hot = pd.get_dummies(df, sparse=False)\n",
    "    cats = label.select_dtypes(include=['object'])\n",
    "\n",
    "    # Apply Label Encoder to each column\n",
    "\n",
    "    label.loc[:, cats.columns] = encode_categorical(label.loc[:, cats.columns], method='label')\n",
    "    \n",
    "    # If target column is not categorical, labels will only be one column\n",
    "    if df.dtypes[target_column] == object:\n",
    "        n_unique = df[target_column].unique().shape[0] - 1\n",
    "    else:\n",
    "        n_unique = 1\n",
    "    \n",
    "    x_ohe, y_ohe = one_hot.iloc[:,:-n_unique], one_hot.iloc[:,-n_unique:]\n",
    "    x_label, y_label = label.iloc[:,:-1], label.iloc[:,-1]\n",
    "    \n",
    "    #print(f'{file}: xcols: {len(x_label)} ycols: {len(y_label)}')\n",
    "    #print(one_hot)\n",
    "    print(f'Training on {file}')\n",
    "\n",
    "    score = train(x_ohe, y_ohe, method='knn', metric='acc')\n",
    "    print(f'\\tOnehot avg: {score}')\n",
    "    score = train(x_label, y_label, method='forest', metric='acc')\n",
    "    print(f'\\tlabel avg: {score}')\n",
    "    print('\\n')\n",
    "    ## There is a slight difference in performance (label encoder usually better by a bit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9237acb9-d3f7-46f9-8114-72f6010104c9",
   "metadata": {},
   "source": [
    "## P3\n",
    "Will feature binning provide performance improvement? When is binning useful (which models or which kinds of datasets)?\n",
    "\n",
    "Loop through each column in the dataframe and bin individually.\n",
    "We use LabelEncoder for categorical features on both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22dcdbe8-67ee-4764-8212-9f24ea33daa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on abalone.data\n",
      "train: abalone.data: avg: 0.7570028364323983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: abalone.data: avg: 0.22193364467237772\n",
      "\n",
      "\n",
      "Training on bands.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: bands.data: avg: 0.7522935779816514\n",
      "test: bands.data: avg: 0.7634726469588855\n",
      "\n",
      "\n",
      "Training on biodeg.csv\n",
      "train: biodeg.csv: avg: 0.8293838862559241\n",
      "test: biodeg.csv: avg: 0.8625592417061612\n",
      "\n",
      "\n",
      "Training on covtype.data\n",
      "train: covtype.data: avg: 0.9399203455997348\n",
      "test: covtype.data: avg: 0.9430166675103223\n",
      "\n",
      "\n",
      "Training on dataset\n",
      "train: dataset: avg: 0.8705780249410179\n",
      "test: dataset: avg: 0.8752140208965284\n",
      "\n",
      "\n",
      "Training on eeg_eye_state.arff\n",
      "train: eeg_eye_state.arff: avg: 0.5511348464619491\n",
      "test: eeg_eye_state.arff: avg: 0.8956608811749\n",
      "\n",
      "\n",
      "Training on heart_2020_cleaned.csv\n",
      "train: heart_2020_cleaned.csv: avg: 0.8967463531324755\n",
      "test: heart_2020_cleaned.csv: avg: 0.8788849106458827\n",
      "\n",
      "\n",
      "Training on HTRU_2.csv\n",
      "train: HTRU_2.csv: avg: 0.9703859571897521\n",
      "test: HTRU_2.csv: avg: 0.9787675312694628\n",
      "\n",
      "\n",
      "Training on income_evaluation.csv\n",
      "train: income_evaluation.csv: avg: 0.8259574406280994\n",
      "test: income_evaluation.csv: avg: 0.8495132113395588\n",
      "\n",
      "\n",
      "Training on phpAmSP4g.arff\n",
      "train: phpAmSP4g.arff: avg: 0.9595714951094549\n",
      "test: phpAmSP4g.arff: avg: 0.9525229001707809\n",
      "\n",
      "\n",
      "Training on Raisin_Dataset.arff\n",
      "train: Raisin_Dataset.arff: avg: 0.821111111111111\n",
      "test: Raisin_Dataset.arff: avg: 0.8566666666666667\n",
      "\n",
      "\n",
      "Training on spambase.data\n",
      "train: spambase.data: avg: 0.751793655289619\n",
      "test: spambase.data: avg: 0.9428383609498182\n",
      "\n",
      "\n",
      "Training on UCI_Credit_Card.csv\n",
      "train: UCI_Credit_Card.csv: avg: 0.7860333333333334\n",
      "test: UCI_Credit_Card.csv: avg: 0.8074\n",
      "\n",
      "\n",
      "Training on WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
      "train: WA_Fn-UseC_-Telco-Customer-Churn.csv: avg: 0.7772269581908511\n",
      "test: WA_Fn-UseC_-Telco-Customer-Churn.csv: avg: 0.7789275719401251\n",
      "\n",
      "\n",
      "Training on WineQT.csv\n",
      "train: WineQT.csv: avg: 0.5792040144028192\n",
      "test: WineQT.csv: avg: 0.6456331877729259\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    df = load(file, False if file in no_headers else True)\n",
    "    binned = df.copy(deep=True)\n",
    "    # TODO: fix arcene random space unable to parse\n",
    "    if file == 'arcene_train.data':\n",
    "        continue\n",
    "    # Bin each column individually, use LabelEncoder for categorical\n",
    "    for column in binned.columns:\n",
    "        if (binned[column].dtype.name == 'int64'\n",
    "           or binned[column].dtype.name == 'float64'):\n",
    "            #n_unique = binned[column].unique() \n",
    "            binned[column]= pd.cut(binned[column], 5, labels=False, duplicates='drop')\n",
    "            #binned[column].fillna(0, inplace=True)\n",
    "\n",
    "            if binned[column].isnull().values.any():\n",
    "                binned[colum] = 0\n",
    "        #elif check if column is categorical\n",
    "        elif binned[column].dtype.name == 'object':\n",
    "            binned[column] = encode_categorical(binned[column], method='label')\n",
    "            df[column] = encode_categorical(df[column], method='ordinal')\n",
    "\n",
    "    # Train\n",
    "    x_bin, y_bin = binned.iloc[:, :-1], binned.iloc[:, -1]\n",
    "    x_label, y_label = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "    \n",
    "    print(f'Training on {file}')\n",
    "    score = train(x_bin, y_bin, method='forest', metric='acc')\n",
    "    print(f'train: {file}: avg: {score}')\n",
    "    \n",
    "    score = train(x_label, y_label, method='forest', metric='acc')\n",
    "    print(f'test: {file}: avg: {score}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e941f-c7b6-49e2-9f0b-db9271a52a80",
   "metadata": {},
   "source": [
    "## P4\n",
    "Compare the performance of 6 different categorical feature encoding methods based on Random Forest, XGBoost LightGBM, MLP, SVM. Which of the 6 encoding methods is better?\n",
    "TODO: Finish implementing neural network (missing dataloader)\n",
    "\n",
    "Models to test: \n",
    "1. One hot encoding\n",
    "2. Label Encoding\n",
    "3. Feature Hasing\n",
    "4. Frequency Encoding\n",
    "5. Target Encoding\n",
    "6. Leave One Out Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a8671b37-af75-4c5f-850e-b0194e58641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking abalone.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t(onehot, forest): 0.23222273157035214\n",
      "\t(onehot, xgboost): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:525: FutureWarning: Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1357, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25], got [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 27]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1357, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26], got [ 1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 26 27 29]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1357, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27], got [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 29]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Andres Ponce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1357, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25], got [ 2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 26\n",
      " 27 29]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, <module 'lightgbm' from 'C:\\\\Users\\\\Andres Ponce\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\lightgbm\\\\__init__.py'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m labelIndex \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m enc_train, enc_test \u001b[38;5;241m=\u001b[39m encoded\u001b[38;5;241m.\u001b[39miloc[:,:\u001b[38;5;241m-\u001b[39mlabelIndex], encoded\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m-\u001b[39mlabelIndex:]\n\u001b[1;32m---> 18\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelName\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(x, y, method, metric)\u001b[0m\n\u001b[0;32m     36\u001b[0m kf \u001b[38;5;241m=\u001b[39m StratifiedKFold( n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(method)\n\u001b[1;32m---> 38\u001b[0m mean_score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03mmean_score = 0 \u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03mfor i, (train_index, test_index) in enumerate(kf.split(x, y)):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m#print(f'Mean score over validation: {mean_score} using {method}')\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mean_score\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:507\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m\"\"\"Evaluate a score by cross-validation.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <cross_validation>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03m    loss function.\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m scorer \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    510\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    511\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    521\u001b[0m )\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:448\u001b[0m, in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m\"\"\"Determine scorer from user options.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03mA TypeError will be thrown if the estimator cannot be scored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;124;03m    ``scorer(estimator, X, y)``.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    449\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator should be an estimator implementing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method, \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m was passed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m         \u001b[38;5;241m%\u001b[39m estimator\n\u001b[0;32m    451\u001b[0m     )\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scoring, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_scorer(scoring)\n",
      "\u001b[1;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, <module 'lightgbm' from 'C:\\\\Users\\\\Andres Ponce\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\lightgbm\\\\__init__.py'> was passed"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    print(f'Checking {file}')\n",
    "    df = load(file, header = False if file in no_headers else True)\n",
    "    cats = df.select_dtypes(include=['object'])\n",
    "    for method in ceMethods:\n",
    "        # Encode features\n",
    "        encoded = df.copy()\n",
    "        \n",
    "    \n",
    "        encoded = encode_categorical(encoded, method=method)\n",
    "     \n",
    "            \n",
    "        for modelName in modelNames:\n",
    "            # Number of class columns, necessary for OHE\n",
    "            #labelIndex = len(df.iloc[:,-1].unique()) if method == 'onehot' else 1\n",
    "            labelIndex = 1\n",
    "            enc_train, enc_test = encoded.iloc[:,:-labelIndex], encoded.iloc[:,-labelIndex:]\n",
    "            score = train(enc_train, enc_test, modelName)\n",
    "            print(f'\\t({method}, {modelName}): {score}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d41521-2aa7-4487-afb4-05ab54bc0265",
   "metadata": {},
   "source": [
    "## P5\n",
    "Which combinations of numerical and categorical feature transformation methods generally lead to better results?\n",
    "\n",
    "Here we can test the different numerical and categorical methods on each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41309118-82c9-45a7-901d-f5486a76c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking: covtype.data\n",
      "clip\n",
      "\tclip, label, 0.9424676226708968\n",
      "standard\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m encode_categorical(df[cats\u001b[38;5;241m.\u001b[39mcolumns], method\u001b[38;5;241m=\u001b[39mceMethod)\n\u001b[1;32m     14\u001b[0m x, y \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnumMethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mceMethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(x, y, method, metric)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_train\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgboost\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     43\u001b[0m     y_train \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;66;03m# Class labels should be zero-based\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m     48\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    442\u001b[0m ]\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 185\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m ):\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    411\u001b[0m         splitter,\n\u001b[1;32m    412\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    418\u001b[0m     )\n\u001b[0;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for file in files:\n",
    "    df = load(file, False if file in no_headers else True)\n",
    "    print(f'Checking: {file}')\n",
    "    # Encode only numerical columns\n",
    "    for numMethod in numMethods:\n",
    "        numcats = df.select_dtypes(include=['float64', 'int64'])\n",
    "        scale_features(df[numcats.columns], method=numMethod)\n",
    "        \n",
    "        # Encode only categorical columns\n",
    "        for ceMethod in ceMethods:\n",
    "            cats = df.select_dtypes(include=['object'])\n",
    "            encode_categorical(df[cats.columns], method=ceMethod)\n",
    "            x, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "            score = train(x, y, method='forest')\n",
    "            print(f'\\tNumerical: {numMethod}, Categorical: {ceMethod}, Acc: {score}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9c9e8-0c2d-4455-b794-ede932074f35",
   "metadata": {},
   "source": [
    "## P6\n",
    "If the number of possible categorical values of a feature is high, which encoding method among target encoding, one-hot encoding, and label encoding will have better performance? Why?\n",
    "\n",
    "Go through each file, test each encoding method, and measure the $n$ datasets with most unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "457d5f1f-c076-47c1-86d7-7d43717866f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on abalone.data\n",
      "28\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'continuous-multioutput' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m x, y \u001b[38;5;241m=\u001b[39m df_copy\u001b[38;5;241m.\u001b[39miloc[:,:\u001b[38;5;241m-\u001b[39mn_labels], df_copy\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m-\u001b[39mn_labels:]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mmethod: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menc_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,  max unique categories: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_uniques\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(x, y, method, metric)\u001b[0m\n\u001b[0;32m     35\u001b[0m kf \u001b[38;5;241m=\u001b[39m StratifiedKFold( n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m mean_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kf\u001b[38;5;241m.\u001b[39msplit(x, y)):\n\u001b[0;32m     39\u001b[0m     model \u001b[38;5;241m=\u001b[39m get_model(method)\n\u001b[0;32m     40\u001b[0m     x_train, x_test \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39miloc[train_index,: ], x\u001b[38;5;241m.\u001b[39miloc[test_index, :]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:340\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    334\u001b[0m         (\n\u001b[0;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    336\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    338\u001b[0m     )\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:86\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     84\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m     85\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[0;32m     87\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[0;32m     88\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:709\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 709\u001b[0m     test_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits):\n\u001b[0;32m    711\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m test_folds \u001b[38;5;241m==\u001b[39m i\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    650\u001b[0m allowed_target_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_of_target_y \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_target_types:\n\u001b[1;32m--> 652\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported target types are: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    654\u001b[0m             allowed_target_types, type_of_target_y\n\u001b[0;32m    655\u001b[0m         )\n\u001b[0;32m    656\u001b[0m     )\n\u001b[0;32m    658\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y)\n\u001b[0;32m    660\u001b[0m _, y_idx, y_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous-multioutput' instead."
     ]
    }
   ],
   "source": [
    "enc_methods = [#'target',\n",
    "               'onehot',\n",
    "               'label',\n",
    "              ]\n",
    "\n",
    "for file in files:\n",
    "    df = load(file, header=False if file in no_headers else True)\n",
    "    print(f'Training on {file}')\n",
    "    for enc_method in enc_methods:\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        # OHE produces this many label columns\n",
    "        n_labels = df_copy.iloc[:, -1].nunique() if enc_method == 'onehot' else 1\n",
    "        \n",
    "        # Encode df using method\n",
    "        cats = df_copy.select_dtypes(include=['object'])\n",
    "        if cats.empty:\n",
    "            print(f'{file} has not categorical')\n",
    "            continue\n",
    "            \n",
    "        max_uniques = max([len(df_copy[col].unique()) for col in cats.columns])\n",
    "        if enc_method == 'onehot':\n",
    "            print(n_labels)\n",
    "            df_copy = pd.get_dummies(df_copy)\n",
    "        else:\n",
    "            df_copy[cats.columns] = encode_categorical(df_copy[cats.columns], method=enc_method, y=df_copy.iloc[:,-1])\n",
    "            \n",
    "        x, y = df_copy.iloc[:,:-n_labels], df_copy.iloc[:, -n_labels:]\n",
    "\n",
    "        # Train model\n",
    "        score = train(x, y, method='forest')\n",
    "        print(f'\\tmethod: {enc_method},  max unique categories: {max_uniques} score: {score}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e41254b-50f4-4a47-a6d1-f90562936026",
   "metadata": {},
   "source": [
    "## Plot class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "60816f46-f119-40f6-94d9-400e290ae93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abalone.data\n",
      "bands.data\n",
      "biodeg.csv\n",
      "covtype.data\n",
      "dataset\n",
      "eeg_eye_state.arff\n",
      "heart_2020_cleaned.csv\n",
      "HTRU_2.csv\n",
      "income_evaluation.csv\n",
      "phpAmSP4g.arff\n",
      "Raisin_Dataset.arff\n",
      "spambase.data\n",
      "UCI_Credit_Card.csv\n",
      "WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
      "WineQT.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "   \n",
    "fig, axs = plt.subplots(3, 5)\n",
    "fig.suptitle('Class Distribution in Datasets')\n",
    "row, col = 0, 0\n",
    "for i, file in enumerate(files):\n",
    "    print(f'{file}')\n",
    "    df = load(file, False if file in no_headers else True)\n",
    "    row = row + 1 if i % 3 != 0 else 0\n",
    "    col = col + 1 if i % 5 != 0 else 0\n",
    "    \n",
    "    target = df.iloc[:, -1]\n",
    "    names, counts = [],[]\n",
    "    for unique in target.unique():\n",
    "        count = target[target == unique].count()\n",
    "        counts.append(count)\n",
    "        names.append(unique)\n",
    "    #print(names, counts)\n",
    "    axs[row, col].bar( range(len(counts)),counts)      \n",
    "    #plot_imbalance(df, file)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5bfd8-d7bb-44ce-98de-c4cc4699ad07",
   "metadata": {},
   "source": [
    "## Imbalanced data samplers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2331ed6d-f5db-49e5-9011-11a4418847f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imb_sampler(method:str, y=None):\n",
    "    if method == 'nearmiss':\n",
    "        return imblearn.under_sampling.NearMiss(n_neighbors=get_least_frequent(y))\n",
    "    elif method == 'clustercentroids':\n",
    "        return imblearn.under_sampling.ClusterCentroids()\n",
    "    elif method == 'condensednn':\n",
    "        return imblearn.under_sampling.CondensedNearestNeighbour(n_neighbors=get_least_frequent(y))\n",
    "    elif method == 'editednn':\n",
    "        return imblearn.under_sampling.EditedNearestNeighbours(n_neighbors=get_least_frequent(y))\n",
    "    elif method == 'neighbourhoodcleaning':\n",
    "        return imblearn.under_sampling.NeighbourhoodCleaningRule(n_neighbors=get_least_frequent(y))\n",
    "    elif method == 'tomeklinks':\n",
    "        return imblearn.under_sampling.TomekLinks()\n",
    "    elif method == 'onesidedselection':\n",
    "        return imblearn.under_sampling.OneSidedSelection()\n",
    "    elif method == 'smote':\n",
    "        return imblearn.over_sampling.SMOTE()\n",
    "    elif method == 'borderlinesmote':\n",
    "        return imblearn.over_sampling.BorderlineSMOTE()\n",
    "    elif method == 'adasyn':\n",
    "        return imblearn.over_sampling.ADASYN(n_neighbors=get_least_frequent(y))\n",
    "    elif method == 'svmsmote':\n",
    "        return imblearn.over_sampling.SVMSMOTE(k_neighbors=get_least_frequent(y))\n",
    "\n",
    "def get_least_frequent(y:pd.Series):\n",
    "    return min(3, min(y.value_counts()))\n",
    "\n",
    "def get_imb_sample(x:pd.DataFrame, y:pd.Series, s_method:str='nearmiss'):\n",
    "    sampler = get_imb_sampler(us_method, y)\n",
    "    # find least frequent class\n",
    "    \n",
    "    #sampler = sampler(n_neighbors=get_least_frequent(y))\n",
    "    return sampler.fit_resample(x, y)\n",
    "\n",
    "def train_imb(x:pd.DataFrame, y:pd.DataFrame, model='forest', eval_method='prc'): \n",
    "    # TODO: Use OVR classifier to \n",
    "    # Perform K-Fold cross validation'\n",
    "   \n",
    "    n_items = x.shape[0]\n",
    "    kf = StratifiedKFold(n_splits=get_least_frequent(y), shuffle=True)\n",
    "    mean_prec, mean_rec, mean_f, mean_supp = 0, 0, 0, 0\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x, y)):\n",
    "        model = get_model('forest')\n",
    "        x_train, x_test = x.iloc[train_index,: ], x.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "            \n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        preds = model.predict(x_test)\n",
    "        prec,rec,f,supp =  metrics.precision_recall_fscore_support(y_test, preds, zero_division=0)\n",
    "        mean_prec += prec\n",
    "        mean_rec += rec\n",
    "        mean_f += f\n",
    "        mean_supp += supp\n",
    "    return np.array([mean_prec, mean_rec, mean_f, mean_supp], dtype=np.float64).mean(axis=1) / (i)\n",
    "    #print(f'Mean score over validation: {mean_score} using {method}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7948bd-2fc9-4dd5-ad42-ee831d6463fa",
   "metadata": {},
   "source": [
    "## P7\n",
    "Compare the classification performance of \"doing nothing\", 7 undersampling,4 oversampling, and 2 ensemble based methods in presence of class imbalance. Which method works generally best and the worst? Why?\n",
    "\n",
    "Since we are interested in measuring our performance on the minority class, we use precision-recall curve.\n",
    "First we get the training and testing data, and apply the sampling method on only the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d36b3d6-3db4-46c0-958b-ad686510347c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeing: abalone.data: 1\n",
      "Cannot sample with less than two classes.\n",
      "Seeing: bands.data: 2\n",
      "\tUndersampling\n",
      "\tnearmiss mean precision: 1.5, mean recall: 1.6666666666666667 mean fscore: 1.5555555555555554, mean support: 2.0\n",
      "\tclustercentroids mean precision: 0.8333333333333334, mean recall: 1.0 mean fscore: 0.8888888888888888, mean support: 2.0\n",
      "\tcondensednn mean precision: 0.6666666666666666, mean recall: 0.8333333333333334 mean fscore: 0.7333333333333334, mean support: 2.6666666666666665\n",
      "\teditednn mean precision: 1.5095492300493234, mean recall: 1.4704732510288068 mean fscore: 1.4831928860902865, mean support: 84.33333333333333\n",
      "\tneighbourhoodcleaning mean precision: 1.3928515928515928, mean recall: 1.3847736625514404 mean fscore: 1.3814756088377542, mean support: 113.0\n",
      "\ttomeklinks mean precision: 1.353144075563468, mean recall: 1.3492560144625225 mean fscore: 1.350022929279177, mean support: 153.66666666666666\n",
      "\tonesidedselection mean precision: 1.2745098039215685, mean recall: 1.3333333333333333 mean fscore: 1.3010752688172043, mean support: 11.333333333333334\n",
      "\n",
      "\tOversampling\n",
      "\tsmote mean precision: 1.54673721340388, mean recall: 1.5789257626825683 mean fscore: 1.5592074592074592, mean support: 32.0\n",
      "\tborderlinesmote mean precision: 1.5997619047619047, mean recall: 1.6070242656449552 mean fscore: 1.6019929130793258, mean support: 38.333333333333336\n",
      "\tadasyn mean precision: 1.1752442002442003, mean recall: 1.1371100164203611 mean fscore: 1.1273262566512707, mean support: 48.333333333333336\n",
      "\tsvmsmote mean precision: 1.4, mean recall: 1.5 mean fscore: 1.4444444444444444, mean support: 5.0\n",
      "Seeing: biodeg.csv: 3\n",
      "\tUndersampling\n",
      "\tnearmiss mean precision: 1.1909900978449068, mean recall: 1.188185443668993 mean fscore: 1.1877044844082638, mean support: 178.0\n",
      "\tclustercentroids mean precision: 1.2647330978831428, mean recall: 1.2639581256231307 mean fscore: 1.2639389493520017, mean support: 178.0\n",
      "\tcondensednn mean precision: 1.160847260064986, mean recall: 1.133351611831173 mean fscore: 1.1409255217775724, mean support: 145.25\n",
      "\teditednn mean precision: 1.3672412797261795, mean recall: 1.3658985604804865 mean fscore: 1.366456735267945, mean support: 202.5\n",
      "\tneighbourhoodcleaning mean precision: 1.3530871669942914, mean recall: 1.3425982765445532 mean fscore: 1.3472922964588654, mean support: 237.75\n",
      "\ttomeklinks mean precision: 1.2980501556962132, mean recall: 1.288362995638408 mean fscore: 1.2923690764892508, mean support: 250.5\n",
      "\tonesidedselection mean precision: 1.2674569769084942, mean recall: 1.2704206132185614 mean fscore: 1.2682856117744916, mean support: 249.75\n",
      "\n",
      "\tOversampling\n",
      "\tsmote mean precision: 1.2823104432768528, mean recall: 1.280760188424647 mean fscore: 1.2812191122603607, mean support: 247.5\n",
      "\tborderlinesmote mean precision: 1.3008773779075096, mean recall: 1.298618826207114 mean fscore: 1.2995237202951835, mean support: 245.5\n",
      "\tadasyn mean precision: 1.295011721667362, mean recall: 1.2927286781565448 mean fscore: 1.2924654812974103, mean support: 249.75\n",
      "\tsvmsmote mean precision: 1.302738338849774, mean recall: 1.285846579812508 mean fscore: 1.2929161762820156, mean support: 244.5\n",
      "Seeing: covtype.data: 3\n",
      "\tUndersampling\n",
      "\tnearmiss mean precision: 1.3877704627262129, mean recall: 1.3876699767171525 mean fscore: 1.3875812186202758, mean support: 1373.5\n",
      "\tclustercentroids mean precision: 1.2662908613313983, mean recall: 1.2668389017859274 mean fscore: 1.2657787045422562, mean support: 1373.5\n"
     ]
    }
   ],
   "source": [
    "under_sampling_methods = ['nearmiss',\n",
    "                          'clustercentroids',\n",
    "                          'condensednn',\n",
    "                          'editednn',\n",
    "                          'neighbourhoodcleaning',\n",
    "                          'tomeklinks',\n",
    "                          'onesidedselection'\n",
    "                         ]\n",
    "\n",
    "over_sampling_methods = ['smote',\n",
    "                         'borderlinesmote',\n",
    "                         'adasyn',\n",
    "                         'svmsmote'\n",
    "                        ]\n",
    "\n",
    "for file in files:\n",
    "    df = load(file, False if file in no_headers else True)\n",
    "    # Encode df\n",
    "    df = encode_categorical(df)\n",
    "    # Split into testing and training set\n",
    "    x, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "    print(f'Seeing: {file}: {get_least_frequent(y)}')\n",
    "\n",
    "    if get_least_frequent(y) < 2:\n",
    "        print('Cannot sample with less than two classes.')\n",
    "        continue\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True)\n",
    "    \n",
    "    # Undersample\n",
    "    print('\\tUndersampling')\n",
    "    for us_method in under_sampling_methods:\n",
    "        x_sample, y_sample  = get_imb_sample(x, y, s_method=us_method)\n",
    "        scores = train_imb(x_sample, y_sample, model='forest')\n",
    "        print(f'\\t{us_method} mean precision: {scores[0]:.3f}, mean recall: {scores[1]:.3f} mean fscore: {scores[2]:.3f}, mean support: {scores[3]:.3f}')\n",
    "    print('\\n\\tOversampling')\n",
    "    for os_method in over_sampling_methods:\n",
    "        # Do the same thing\n",
    "        x_sample, y_sample = get_imb_sample(x, y, s_method=os_method)\n",
    "        scores = train_imb(x_sample, y_sample, model='forest')\n",
    "        print(f'\\t{os_method} mean precision: {scores[0]:.3f}, mean recall: {scores[1]:.3f} mean fscore: {scores[2]:.3f}, mean support: {scores[3]:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f01f5aa-126c-45d8-8cc5-0090af5b91af",
   "metadata": {},
   "source": [
    "## P8\n",
    "Can you find the datasets on which SMOTE-based oversampling works best? What does the data look like? Why?\n",
    "\n",
    "We can use the results from the previous problem, and describe each of the dataframes to find some patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33825105-7a3a-48b3-9542-dd274479d07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
