{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fbeb7ec-697d-406a-bc49-75d982115940",
   "metadata": {},
   "source": [
    "# Data Science Homework 4\n",
    "Try different imbalanced classification datasets using $k$-fold cross validation and various classification methods.\n",
    "TODO List:\n",
    "- Make sure we can open all the data as either DataFrame or nparray\n",
    "- Handle categorical data (tokenize, one-hot encoding, ....)\n",
    "- Split each dataset into training and testing dataset.\n",
    "- Perform any necessary sampling, imputaiton, encoding techniques depending on dataset\n",
    "- Perform 5-fold cross-validation to select datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3197ea94-1d37-4113-baf2-de091cac66a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abalone.data', 'arcene_train.data', 'biodeg.csv', 'covtype.data', 'dataset', 'eeg_eye_state.arff', 'heart_2020_cleaned.csv', 'HTRU_2.csv', 'income_evaluation.csv', 'phpAmSP4g.arff', 'Raisin_Dataset.arff', 'spambase.data', 'UCI_Credit_Card.csv', 'WA_Fn-UseC_-Telco-Customer-Churn.csv', 'WineQT.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import category_encoders as ce # sklearn library\n",
    "import xgboost\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "DATA_DIR = './data'\n",
    "files = os.listdir(DATA_DIR)\n",
    "if '.ipynb_checkpoints' in files:\n",
    "    files.remove('.ipynb_checkpoints')\n",
    "\n",
    "special_delims = { 'arcene_train.data': ' '}\n",
    "no_headers = ['covtype.data', 'arcene_train.data']\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4815b9fb-5923-4120-9df7-0bbf3ffe073a",
   "metadata": {},
   "source": [
    "## Load datasets\n",
    "Some datasets are in csv format, others have just the data. First convert to `DataFrame`s to allow for numeric, categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66cd7606-affa-4a6b-a7de-265d2703dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load(name, header=True):\n",
    "    sep = special_delims[name] if name in special_delims else ','\n",
    "    name = os.path.join(DATA_DIR, name)\n",
    "    if header:\n",
    "        df = pd.read_csv(name, sep=sep)\n",
    "    else:\n",
    "        df = pd.read_csv(name, header=None, sep=sep)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6ed6f-5619-4bd8-bd2b-ec3f64277958",
   "metadata": {},
   "source": [
    "## Encode Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a3a02f-649f-45ea-9efc-a9c014157915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(data:pd.DataFrame, method='ordinal'):\n",
    "    if method == 'ordinal':\n",
    "        encoder = ce.OrdinalEncoder()\n",
    "    elif method == 'onehot':\n",
    "        encoder = ce.OneHotEncoder()\n",
    "    elif method == 'label':\n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "    return encoder.fit_transform(data)\n",
    "\n",
    "def scale_features(data:pd.DataFrame, method='standard') -> pd.DataFrame:\n",
    "    if method == 'standard':\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "    elif method == 'minmax':\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "    return scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb65dd-2d12-4851-9783-037c307c731b",
   "metadata": {},
   "source": [
    "## Train model:\n",
    "The evalutation should be fixed on 5-fold cross validation, choose from `RandomForest`, `GBDT`, `XGBoost`,`LightBGM`, `CatBoost`, `KNN`, `Logistic Regression`,`MLP`, `SVM`.\n",
    "\n",
    "Train a new model every iteration of the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f52818bb-a52f-4e49-90d3-aa1008e90157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model(method):\n",
    "    if method == 'xgboost':\n",
    "        model = xgboost.XGBClassifier(5)\n",
    "    elif method == 'knn':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif method == 'forest':\n",
    "        model = RandomForestClassifier(10)\n",
    "    else:\n",
    "        print(f'{method} not supported.')\n",
    "        model = None\n",
    "    return model\n",
    "\n",
    "def get_metric(method):\n",
    "    if method == 'acc':\n",
    "        met = metrics.accuracy_score\n",
    "    elif method == 'auc':\n",
    "        met = metrics.auc\n",
    "    elif method == 'roc_auc':\n",
    "        met = metrics.roc_auc_score\n",
    "    elif method == 'f1':\n",
    "        met = metrics.f1_score\n",
    "    return met\n",
    "\n",
    "def train(x, y, method='xgboost', metric='acc'):\n",
    "    # Perform K-Fold cross validation\n",
    "    metric = get_metric(metric)\n",
    "    n_items = x.shape[0]\n",
    "    kf = KFold( n_splits=5, shuffle=True)\n",
    "    \n",
    "    mean_score = 0 \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "        model = get_model(method)\n",
    "        x_train, x_test = x.iloc[train_index,: ], x.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        if method == 'xgboost':\n",
    "            y_train -= 1 # Class labels should be zero-based\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        preds = model.predict(x_test)\n",
    "        score = metric(y_test, preds)\n",
    "        mean_score += score\n",
    "        #print(f'\\t{mean_score}')\n",
    "        \n",
    "    mean_score /= (i+1)\n",
    "    #print(f'Mean score over validation: {mean_score} using {method}')\n",
    "\n",
    "    return mean_score\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570aa398-74ca-476c-ab9c-1b703a1cae20",
   "metadata": {},
   "source": [
    "## P1: How does feature scaling (e.g. performing normalization) affect performance?\n",
    "With standardization we apply the formula\n",
    "$$x' = \\frac{x - \\mu}{\\sigma}$$\n",
    "so that we have 0 mean in the training data.\n",
    "\n",
    "For One-hot Encoding we should not use this with tree-based models. For these models we can use label encoding, feature-hashing.\n",
    "We should first encode the categorical values, then train the models on all our datasets both with feature scaling and without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d8aa7e-001d-4e4b-9b41-400240cce3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    \n",
    "    df = load(file, False if file in no_headers else True)\n",
    "    # Encode categorical columns\n",
    "    cats = df.select_dtypes(include=['object'])\n",
    "    df[cats.columns] = encode_categorical(cats)\n",
    "    \n",
    "    control = df.copy(deep=True) # Compare with standardized dataset\n",
    "\n",
    "    df, labels = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "    control, c_labels = control.iloc[:, :-1], control.iloc[:, -1]\n",
    "    \n",
    "    # Feature scaling\n",
    "    df = pd.DataFrame(scale_features(df))\n",
    "    \n",
    "    # Train model\n",
    "    print(f'Training on {file}')\n",
    "    score = train(df, labels, method='knn', metric='acc')\n",
    "    print(f'train: {file}: avg: {score}')\n",
    "   \n",
    "    score = train(control, c_labels, method='knn', metric='acc')\n",
    "    print(f'test: {file}: avg: {score}')\n",
    "    print('\\n')\n",
    "    # The performance is mostly the same across models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aad0b2",
   "metadata": {},
   "source": [
    "## P2 When using tree-based algorithms, will usng one-hot encoding for categorical features generate worse performance than using label encoding? Why?\n",
    "One-hot encoding transforms inputs with a range of $(1,\\dots,n)$. This method generates extra columns and usually results in a sparse matrix.\n",
    "\n",
    "Label Encoding adds replaces each unique class name with an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc1a45-e699-414f-8259-00d78398f75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on abalone.data\n",
      "train: abalone.data: avg: 0.1888892072314701\n",
      "test: abalone.data: avg: 0.2300664699309515\n",
      "\n",
      "\n",
      "No categorical in arcene_train.data\n",
      "\n",
      "Training on biodeg.csv\n",
      "train: biodeg.csv: avg: 0.49857819905213263\n",
      "test: biodeg.csv: avg: 0.8075829383886255\n",
      "\n",
      "\n",
      "No categorical in covtype.data\n",
      "\n",
      "Training on dataset\n",
      "train: dataset: avg: 0.3476457701381867\n",
      "test: dataset: avg: 0.8792568250758341\n",
      "\n",
      "\n",
      "No categorical in eeg_eye_state.arff\n",
      "\n",
      "Training on heart_2020_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    df = load(file, False if file in no_headers else True)\n",
    "    target_column = df.columns[-1]\n",
    "    label = df.copy(deep=True) # Use label encoding\n",
    "    \n",
    "    cats = df.select_dtypes(include=['object'])\n",
    "\n",
    "    # Ignore files w/ no categorical data, otherw encoder error\n",
    "    if cats.empty:\n",
    "        print(f'No categorical in {file}\\n')\n",
    "        continue\n",
    "        \n",
    "    n_unique = df[target_column].unique().shape[0] # Num of unique items in target column\n",
    "\n",
    "    one_hot = pd.get_dummies(df)\n",
    "    cats = label.select_dtypes(include=['object'])\n",
    "    #print(f'{file}: {target_column}')\n",
    "    # Apply Label Encoder to each column\n",
    "    for column in cats.columns:\n",
    "        label[column] = encode_categorical(label[column], method='label')\n",
    "        \n",
    "    # If target column is not categorical, labels will only be one column\n",
    "    if df.dtypes[target_column] == object:\n",
    "        n_unique = df[target_column].unique().shape[0]\n",
    "    else:\n",
    "        n_unique = 1\n",
    "    \n",
    "    x_ohe, y_ohe = one_hot.iloc[:,:-n_unique], one_hot.iloc[:,-n_unique:]\n",
    "    x_label, y_label = label.iloc[:,:-1], label.iloc[:,-1]\n",
    "    \n",
    "    #print(f'{file}: xcols: {len(x_label)} ycols: {len(y_label)}')\n",
    "    #print(one_hot)\n",
    "    \n",
    "    print(f'Training on {file}')\n",
    "    score = train(one_hot, labels, method='knn', metric='acc')\n",
    "    print(f'train: {file}: avg: {score}')\n",
    "    \n",
    "    score = train(x_label, y_label, method='knn', metric='acc')\n",
    "    print(f'test: {file}: avg: {score}')\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9958ab8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
