\documentclass[12pt]{article}
\usepackage{amsmath, amsfonts}
\usepackage{graphicx}
\usepackage{tabularx}

\graphicspath{{./img}}
\usepackage[margin=1in]{geometry}

\usepackage{xeCJK}
\setCJKmainfont{WenQuanYi Micro Hei Mono}

\usepackage{algorithm}

\usepackage[backend=biber,style=ieee]{biblatex}
\addbibresource{report.bib}

\begin{document}
\title{Data Science Homework 4}
\author{Andr\'es Ponce,
\and
彭思安
\and
P76107116
}

\begin{document}
\maketitle
\section{Introduction}
Our data's properties will determine the pre-processing steps we take to ensure our 
model performs well with new data.
For instance, since machine learning methods can for the most part deal only with
numerical values, its is necessary to convert string-based values into numbers.
Such methods range from just assigning a numerical value to a class index to 
using hash tables to store indices of the column to which it belongs.

Another common issue in the data processing stage is imbalanced data.
This happens when some categories in our data happen less often than others,
sometimes much less often.
These categories are known as \textbf{minority class}, and more common
classes or categories are known as \textbf{majority class}.
To ensure our model is exposed to the category, we can either remove elements
from the majority class with \textbf{undersampling methods} or create new samples
from the minority class using \textbf{oversampling methods}.

In this assignment we investigate the relation between datasets and different
encoding and sampling methods.
First, we describe the datasets used, then conduct experiments on different
combinations of encoding and sampling methods.

\section{Datasets}
% Make the table here
% Plot the class imbalances

\section{First Question}

\end{document}
