\documentclass[11pt]{scrartcl}
\input{template/structure.tex}
\usepackage{xeCJK}
\usepackage{amsmath}
\usepackage{breqn}
\setCJKmainfont{Noto Serif CJK TC}
\newcommand{\vect}{\boldsymbol}
\title{ 
	\normalfont\normalsize
	\textsc{National Cheng Kung University}\\
	\vspace{25pt}
	\rule{\linewidth}{0.5pt}\\
	\vspace{20pt}
	{\huge Optimization Design Homework 1}\\
	\vspace{12pt}
	\rule{\linewidth}{2pt}\\
	\vspace{12pt}
}
\author{\Large Andr\'es Ponce \and 彭思安 \and P76107116}
\date{\normalsize\today}

\begin{document}
\maketitle
\section{Find the stationary points for the following functions. 
Also identify(for each stationary point), the local maximum, minimum,
or neither (by using second order derivative or Hessian matrix.)}

\subsection{$f(x) = x^{3}\exp(-x^2)$, for $-2<x<2$.}
The stationary points are those where $f'(x) = 0$, so we first find
the first derivative.
By using the product rule,

\begin{equation}
\label{eq:1aFirstDer}
f'(x) = 3x^{2}\exp(-x^{2}) -2x^{4}\exp(-x^{2}) = -x^2 \exp(-x^{2})(2x^4 - 3x^2)
\end{equation}

which is zero at $x=0$, and by solving $2x^4 - 3x^2$ we get the other roots $x=\pm\frac{\sqrt{3}}{\sqrt{2}}$.
Theorem 2.2 gives the sufficient condition for a minimum or maximum point for
single variables.
We must find a point where $f^{m}(x^{*}) \neq 0$, so we find $f''(x)$.
We again use the product rule on Equation~\ref{eq:1aFirstDer} and factor 
the result to obtain

\begin{equation}
	\label{eq:1aSecondDer}
	f''(x) = -x\exp(-x^{2})(4x^4 + 2x^2 -6)
\end{equation}
where $f''(\frac{\sqrt{3}}{\sqrt{2}}) < 0$ and $f''(-\frac{\sqrt{3}}{\sqrt{2}}) > 0$ However, $f''(0) = 0$,
so we find the third derivative by using the same procedure
\begin{equation}
\label{eq:1aThirdDer}
f'''(x) = -x\exp(-x^{2})(20x^3 + 6x + 8x^4 + 4x^2 -12) - 6\exp(-x^2)
\end{equation}
where $f'''(0)=6$, however since $n=3$, $0$ does not correspond to either
a maximum nor minimum point.
In the end, $-\frac{\sqrt{3}}{\sqrt{2}}$ is a minimum, $0$ is neither, and 
$\frac{\sqrt{3}}{\sqrt{2}}$ is a maximum.

\subsection{$f(x, y) = -x^2 -3y^2 + 12xy$}
For a multivariable equation, solving for $x$ and $y$ in the partial derivatives will give us
the stationary points.
\begin{equation}
	\label{eq:1bxFirstDer}
	\frac{\partial f}{\partial x} = -2x + 12y
\end{equation}

\begin{equation}
	\label{eq:1byFirstDer}
	\frac{\partial f}{\partial y} = -6y + 12x
\end{equation}
We first solve for $y$ in Equation~\ref{eq:1byFirstDer} and we get $y=2x$.
Substituing for $y$ in Equation~\ref{eq:1bxFirstDer}, we get 
$$-2x + 24x = 22x$$
$$22x = 0$$
which means $x=0$.
Substituting again $x=0$ in Equation~\ref{eq:1byFirstDer} we get $-6y=0$ which means
$y=0$.
The stationary point for $f$ is $(0, 0)$.

To determine the nature of the stationary points, we have to find the Hessian matrix,
which involves finding the second order partial derivatives.
\begin{equation}
	\frac{\partial^{2} f}{\partial^{2} x}=-2\quad \frac{\partial^{2}f}{\partial^{2}y} = -6
\end{equation}

\begin{equation}
	\frac{\partial^{2} f}{\partial y\partial x}=12\quad \frac{\partial^{2}f}{\partial x\partial y} = 12
\end{equation}
and build the Hessian matrix
$$
\boldsymbol{H} = 
\begin{bmatrix}
	-2 & 12\\
	12 & -6
\end{bmatrix}
$$
We can check for positive or negative definiteness by looking at the sign of $|\boldsymbol{H}_1|$ and $|\boldsymbol{H}_{2}|$.
Here $|\boldsymbol{H}_1| = -2$ and $|\boldsymbol{H}_2| = (-6)(-2) -(12)(12) = -136$.
Since both determinants are negative, we conclude $(0, 0)$ is neither a maximum nor minimum of $f$.

\section{A quadratic function of $n$ variables has the following standard form
		$$f(\vect{x}) = \vect{x}^{T}A\vect{x}/2 + \vect{b}^{T}\vect{x} +c$$, 
		where $\vect{x}$ is the vector containing the $n$ variables.
		Vector $\vect{b}$($n\times1$) and symmetric matrix $\vect{A}$($n\times n$) contain
		constant coefficients.
		For the following two quadratic functions $f_a (\vect{x})=x_{1}^{2}+2x_{1}x_{2}+3x_{2}^{2}$
		and $f_b (\vect{x})=-x_{1}^{2}-x_{2}^{2}-x_{3}^{2}+2x_{1}x_{2}+6x_{1}x_{3}+4x_{1}-5x_{3}+7$, please
}
\subsection{Rewrite these functions in the standard quadratic function form.}
In the standard quadratic form, the first product $\vect{x}^{T}\vect{A}\vect{x}$ produces the quadratic terms and
the combinations $\vect{x}_i\vect{x}_j, i\neq j$.
For $f_a$,
on the diagonals of $\vect{A}$ we place the coefficients of the quadratic terms, in this case $2$ and $6$.
Outside of the diagonals we place the half of the combinations $\vect{x}_1\vect{x}_2$, or $2$ in this case.
The product $\vect{b}^{T}\vect{x}$ would take care of any single first order variables $x_{i}, i=1,2$; however
$f_a$ does not have such factors.
The final quadratic form for $f_a(\vect{x})$ is 
\begin{equation}
	f_a(\vect{x}) = 
	\frac{1}{2}
	\begin{bmatrix}
		x_1 & x_2\\
	\end{bmatrix}
	\begin{bmatrix}
			2 & 2 \\
			2 & 6 
	\end{bmatrix}
	\begin{bmatrix}
			x_1 \\
			x_2
	\end{bmatrix}
	+
	\begin{bmatrix}
		0 & 0\\
	\end{bmatrix}
	\begin{bmatrix}
		x_1\\
		x_2
	\end{bmatrix}
	+ 0
\end{equation}

The process is similar for $f_b$.
On the diagonals we place the coefficients of the second order components, and off the diagonals the 
coefficients of $x_i x_j, i\neq j$.
Next, $\vect{b}$ will contain the first order coefficients, here $4, 0, -5$ for $x_1, x_2, x_3$, respectively.
The standard quadratic formula for $f_b(\vect{x})$ is
\begin{equation}
	f_b(\vect{x}) = 
	\frac{1}{2}
	\begin{bmatrix}
			x_1 & x_2 & x_3\\
	\end{bmatrix}
	\begin{bmatrix}
			-2 & 2 & 6\\
			2 & -2 & 0\\
			6 & 0 & -2
	\end{bmatrix}
	\begin{bmatrix}
		x_1\\
		x_2\\
		x_3
	\end{bmatrix}
	+
	\begin{bmatrix}
		4 & 0 & -5\\
	\end{bmatrix}
	\begin{bmatrix}
			x_1\\
			x_2\\
			x_3
	\end{bmatrix}
	+ 7
\end{equation}
\subsection{For these functions, show that $\nabla f = A\vect{x}+b$.}
The gradient vector $\nabla f(\vect{x})$ is the vector containing the partial derivatives
$\frac{\partial f}{\partial x_i}$.

$$
\nabla f_a(\vect{x}) =
\begin{bmatrix}
	2x_1 + 2x_2 \\
	2x_1 + 6x_2
\end{bmatrix}
$$
and the product $A\vect{x} + b$ is 
$$
\begin{bmatrix}
	2 & 2\\
	2 & 6
\end{bmatrix}
\begin{bmatrix}
	x_1\\
	x_2
\end{bmatrix}
+
\begin{bmatrix}
	0\\
	0
\end{bmatrix}
=
\begin{bmatrix}
	2x_1 + 2x_2\\
	2x_1 + 6x_2
\end{bmatrix}
$$
which shows that $\nabla f_a(\vect{x}) = A\vect{x} + \vect{b}$.

For the second equation
$$
\nabla f_b (\vect{x}) = 
\begin{bmatrix}
	-2x_1 + 2x_2 + 6x_3 + 4\\
	-2x_2 + 2x_1\\
	-2x_3 + 6x_1 -5
\end{bmatrix}
$$
and the product $A\vect{x}+\vect{b}$ is 
$$
\begin{bmatrix}
	-2 & 2 & 6\\
	2 & -2 & 0\\
	6 & 0 & -2
\end{bmatrix}
\begin{bmatrix}
	x_1\\
	x_2\\
	x_3
\end{bmatrix}
+
\begin{bmatrix}
	4\\
	0\\
	-5
\end{bmatrix}
=
\begin{bmatrix}
	-2x_1 + 2x_2 + 6x_3 + 4\\
	-2x_2 + 2x_1\\
	-2x_3 + 6x_1 -5
\end{bmatrix}
$$

which again shows $\nabla f_b(\vect{x}) = A\vect{x} + \vect{b}$.

\subsection{For these functions, determine whether the matrix $A$ is positive definite,
negative definite, or indefinite.}
The textbook mentions two methods to check whether the matrix is positive definite, negative definite, or
semi-definite.
The first method involves checking the signs of the eigenvalues of $A$.
The second involves checking the sign of the determinants of the submatrices $A_1, A_2,\dots,A_n$.
For $f_a(\vect{x})$ this would be 
\begin{equation*}
|A_1| = |2|\quad\textrm{and}\quad |A_2| =
\begin{vmatrix}
2 & 2\\
2 & 6\\
\end{vmatrix}
= (2)(6) - (2)(2) = 8
\end{equation*}
Since $|A_1|$ and $|A_2|$ are positive, $A$ is positive definite.

%%% TODO: Solve for fb(x)!!!!
For $f_b(\vect{x})$ we repeat the same procedure, we check the signs of $|A_1|,|A_2|$ and $|A_3|$.
\[|A_1| = -2\]
\[|A_2| = (-2)(-2) - (2)(2) = 0\]
\[|A_3| = -2(4) - 2(-4) + 6(-12) = 72\]
Since there are both negative and positive determinants for the submatrices of $A$,
the matrix of $f_b(\vect{x})$ is indefinite.

\section{Minimize the following functions subject to equality and/or inequality
constraints. For problems with inequality constraints, identify the active ones.
To know whether a point is local minimum, perform function evalutation at 2 
nearby points (which satisfy constraints) to show that what you found is local
minimum.}
\subsection{$f(x,y) = 1/(xy)^2$, subject to $x^2 + y^2 = 1$}
Using the Lagrange multiplier method, we first define our Lagrange function $L$
\[L(x, y, \lambda) = \frac{1}{(xy)^2} +\lambda(1-x^2-y^2)\]
and find the partial derivatives of $x, y$, and $\lambda$.
\begin{equation}
	\label{eq:dldx}
	\frac{\partial L}{\partial x} = -2x^{-3}y^{-2} -2\lambda x
\end{equation}
\begin{equation}
	\label{eq:dldy}
	\frac{\partial L}{\partial y} = -2x^{-2}y^{-3}-2\lambda y
\end{equation}
\begin{equation}
	\label{eq:dldlambda}
	\frac{\partial L }{\partial \lambda} = 1-x^2-y^2
\end{equation}
When we solve for $\lambda$ in Equation~\ref{eq:dldx}, we get 
$\lambda = -x^{-4}y^{-2}$.
Substituting for $\lambda$ in Equation~\ref{eq:dldy}, we get
\[-2x^{-2}y^{-3}-2y(-x^{-4}y^{-2})\]
which in the end gives us $y=x$.
Plugging this result in Equation~\ref{eq:dldlambda}, we get the result
\[x = y = \frac{1}{\sqrt{2}}\]
which gives us a value of $4$ in $f$.
To show $(\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}})$ is a local minimum, we 
plot some nearby points.
We chose the points $(0.69, 0.7238)$ and $(0.72, 0.694)$, which lie on either
side of our proposed minimum, and evaluate
\[f(0.69, 0.7238) = 4.009\]
\[f(0.72, 0.694) = 4.005\]
which supports our claim that $(\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}})$ is a minimum.
\subsection{$f(x,y) = x^2 - 2x + y^2- 10y$, 
subject to $-x^2 + y \leq 4$ and $-(x-2)^2 + y \leq 3$}
\end{document}
